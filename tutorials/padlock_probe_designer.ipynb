{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Padlock Probe Designer\n",
    "\n",
    "This notebook implements a pipeline to designe Padlock probes (short oligos) using the `oligo_designer_toolsuite` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the necassary pakages exept from the oligo_designer_toolsuite\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "import yaml\n",
    "from Bio.SeqUtils import MeltingTemp as mt\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the parameters\n",
    "\n",
    "First, we need to define the parameters we want to use to generate the Padlock probes. \n",
    "A possible way to define all the parameters, that is flexible and reusable, is to use a configuration file. \n",
    "For this tutorial we will use the YAML file `padlock_probe_designer_custom.yaml`, which uses a custom gene annotation (GTF file - GFF3 not supported) and genome sequence (fasta file). As an example, we use human gene annotation and genome sequence of chromsome 16. Check out the config file to understand which parameters are required and how the configuration file is structured.\n",
    "If you want to use NCBI or Ensembl gene annotation and genome sequence with automatic file download from their servers, please check out the YAML files `padlock_probe_designer_ncbi.yaml` and `padlock_probe_designer_ensembl.yaml`.\n",
    "\n",
    "Once the configuration file has been set up we have to read its content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"./configs/padlock_probe_designer_custom.yaml\"\n",
    "# config_file = \"./configs/padlock_probe_designer_ncbi.yaml\" # NCBI config\n",
    "# config_file = \"./configs/padlock_probe_designer_ensemble.yaml\" # Ensemble config\n",
    "with open(config_file, 'r') as yaml_file:\n",
    "    config = yaml.safe_load(yaml_file)\n",
    "dir_output = os.path.join(os.path.dirname(os.getcwd()), config[\"dir_output\"]) # create the complete path for the output directory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Genomic Regions for the Oligo and Reference Database\n",
    "\n",
    "Now we can start to build the pipeline. We start with generating the fasta file used as basis for the oligo database and reference database for the alignement methods. *Note: you can use different fasta files to create the oligo and reference database.* From the provided genome annotation (fasta file), specific regions can be extracted. In particular, it is possible to use: \n",
    "\n",
    "- the whole genome\n",
    "- the transcriptome\n",
    "- the coding sequence (CDS)\n",
    "\n",
    "To create specific regions, we need a `CustomGenomicRegionGenerator`, or a class that inherits form it (e.g. `NcbiGenomicRegionGenerator` and `EnsemblGenomicRegionGenerator`) and call the method `generate_transcript_reduced_representation()` to extract the transcriptome in a reduced representation form from the given files. These classes differ on how the the fasta and the GTF (GFF3 not supported) files used are obtained. The first one uses local files while the others dowload them respectively form the NCBI or Ensambl ftp server. *Note: that the GTF file must contain coordinate as well as transcript ID and exon number infomration to generate a transcriptome or coding sequence.* In the output fasta file, the header of each sequence must start with '>' and contain the following information: \n",
    "region_id, additional_information and coordinates (chrom, start, end, strand)\n",
    "\n",
    "Input Format (per sequence):  \n",
    "`>region_id::additional information::chromosome:start-end(strand)`  \n",
    "`sequence`\n",
    "\n",
    "Example:  \n",
    "`>ASR1::transcrip_id=XM456,exon_number=5::16:54552-54786(+)`  \n",
    "`AGTTGACAGACCCCAGATTAAAGTGTGTCGCGCAACAC` \n",
    "\n",
    "To use NCBi or Ensembl files, comment in the respective config files in the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oligo_designer_toolsuite.database import CustomGenomicRegionGenerator, NcbiGenomicRegionGenerator, EnsemblGenomicRegionGenerator\n",
    "\n",
    "# If the custom config file is selected\n",
    "if config[\"source\"] == \"custom\":\n",
    "    region_generator_custom = CustomGenomicRegionGenerator(\n",
    "        annotation_file=config[\"file_annotation\"], \n",
    "        sequence_file=config[\"file_sequence\"], \n",
    "        files_source=config[\"files_source\"], \n",
    "        species=config[\"species\"], \n",
    "        annotation_release=config[\"annotation_release\"], \n",
    "        genome_assembly=config[\"genome_assembly\"],\n",
    "        dir_output=dir_output\n",
    "    )\n",
    "# If the Ncbi config file is selected\n",
    "elif config[\"source\"] == \"ncbi\":\n",
    "    region_generator = NcbiGenomicRegionGenerator(\n",
    "        taxon=config[\"taxon\"],\n",
    "        species=config[\"species\"], \n",
    "        annotation_release=config[\"annotation_release\"], \n",
    "        dir_output=dir_output\n",
    "    )\n",
    "# If the Ensembl config file is generated\n",
    "elif config[\"source\"] == \"ensembl\":\n",
    "    region_generator = EnsemblGenomicRegionGenerator(\n",
    "        species=config[\"species\"], \n",
    "        annotation_release=config[\"annotation_release\"], \n",
    "        dir_output=dir_output\n",
    "    )\n",
    "\n",
    "file_transcriptome = region_generator_custom.generate_transcript_reduced_representation(include_exon_junctions=True, exon_junction_size=2*config[\"oligo_length_max\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oligo sequences generation\n",
    "\n",
    "\n",
    "Next we will generate all the possible oligos with length between the maximum and minimum value given belonging to the genes defined in the config file. For this we intialize the class ``OligoDatabase`` and use the meothod ``create_database()``.  \n",
    "The ``OligoDatabase`` requires a fasta file as input. This fasta file can be created using a ``GenomicRegionGenerator`` (see code in cell above) or a custom fasta file can be provided. The input fasta file needs a header for each sequence, which must start with '>' and contain the following information: \n",
    "region_id, additional_information and coordinates (chrom, start, end, strand), where the region_id is compulsory and the other fileds are opional.\n",
    "\n",
    "Input Format (per sequence):  \n",
    "`>region_id::additional information::chromosome:start-end(strand)`  \n",
    "`sequence`\n",
    "\n",
    "Example:  \n",
    "`>ASR1::transcrip_id=XM456,exon_number=5::16:54552-54786(+)`  \n",
    "`AGTTGACAGACCCCAGATTAAAGTGTGTCGCGCAACAC`  \n",
    "or   \n",
    "`>ASR1`  \n",
    "`AGTTGACAGACCCCAGATTAAAGTGTGTCGCGCAACAC`\n",
    "\n",
    "The generated probes will be saved in a nested dicionary with the following structure: \n",
    "\n",
    "``[gene][oligo_id][oligo_features]``\n",
    "\n",
    "*Note: if you already have a stored database you can load it into an OligoDatabase object by using the ``load_oligo_database()`` function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oligo_designer_toolsuite.database import OligoDatabase\n",
    "\n",
    "# define the database class\n",
    "oligo_database = OligoDatabase(\n",
    "    file_fasta = file_transcriptome,\n",
    "    oligo_length_min = config[\"oligo_length_min\"],\n",
    "    oligo_length_max = config[\"oligo_length_max\"],\n",
    "    min_oligos_per_region = config[\"min_oligos_per_gene\"],\n",
    "    files_source = region_generator_custom.files_source,\n",
    "    species = region_generator_custom.species,\n",
    "    annotation_release = region_generator_custom.annotation_release,\n",
    "    genome_assembly = region_generator_custom.genome_assembly,\n",
    "    n_jobs = 2,\n",
    "    dir_output=dir_output\n",
    ")\n",
    "\n",
    "# read the genes file\n",
    "if config[\"file_genes\"] is None:\n",
    "    warnings.warn(\n",
    "        \"No file containing the genes was provided, all the genes are ussed to generate the probes. This chioce can use a lot of resources.\"\n",
    "    )\n",
    "    genes = None\n",
    "else:\n",
    "    with open(config[\"file_genes\"]) as handle:\n",
    "        lines = handle.readlines()\n",
    "        genes = [line.rstrip() for line in lines]\n",
    "        \n",
    "# generate the oligo sequences from gene transcripts\n",
    "oligo_database.create_database(region_ids=genes) \n",
    "\n",
    "# alternative: load database from file\n",
    "# oligo_database.load_oligo_database(file_database)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary structure\n",
    "\n",
    "Here is an example of how the nested dictionary is structured for one oligo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AARS1': {'AARS1_16:70265624-70265662(-)': {'sequence': Seq('GAGACACTGCTTGGCTCCTCTATGACACCTATGGGTTT'), 'chromosome': '16', 'start': [70265624], 'end': [70265662], 'strand': '-', 'length': 38, 'additional_information_fasta': ['transcript_id=NM_001605.3,exon_number=10;transcript_id=XM_047433666.1,exon_number=10']}}}\n"
     ]
    }
   ],
   "source": [
    "gene = list(oligo_database.database.keys())[0]\n",
    "oligo_id = list(oligo_database.database[gene].keys())[0]\n",
    "\n",
    "sample_oligos_DB = {gene: {oligo_id: oligo_database.database[gene][oligo_id]}}\n",
    "print(sample_oligos_DB)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and write\n",
    "\n",
    "The ``OligoDatabase`` class deals with everything that is related to the management of the database. In particular, beyond creatig the database, it can also read and write the oligo sequences in a **tsv** fromat. The methods `load_database()` and `write_database()`,  have exactly this purpose. It is also possible to write the sequences as a fasta file with the method ``write_fasta_from_database()``.\n",
    "\n",
    "This allows us to save the current state of the database during the pipeline and to retrive it form a previous stage if an error uccurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"write_intermediate_steps\"]:\n",
    "    file_database = oligo_database.write_database(filename=\"oligo_database_initial.txt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Property filters\n",
    "\n",
    "Once all the possible sequences are created, we apply a first filtering step based on the sequence properties (e.g. melting temperature or GC content). This is useful to reduce the amount of sequences we have to deal with in the next stages and discard all the sequences that are not suited for the experiment.\n",
    "\n",
    "Each property filter is a class that inherits from the Abstact Base Class `PropertyFilterBase` They have a method called `apply` that takes the `OligoDatabase.database` dictionary and returns it filtered. To make this process smooth and modular the wrapper class `PropertyFilter` allows to apply several filters one after the other. It takes as input a list of filter classes and an `OligoDatabase` object and applies sequentially all the filters and returns the final filterd version of the database. Additionally, all the necessary sequence features computed by the filters are stored in the `OligoDatabase.database` for possible later use. \n",
    "\n",
    "*Note: the filters are applied in the order they are given as input. Hence, filter with fast computations should be listed first, i.e. apply GC content filter before melting temperature filter, to reduce runtime.*\n",
    "\n",
    "To create new property filters follow the Abstact Base Class requirements in `PropertyFilterBase`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oligo_designer_toolsuite.oligo_property_filter import (\n",
    "    PropertyFilter,\n",
    "    MaskedSequences,\n",
    "    GCContent, \n",
    "    MeltingTemperatureNN, \n",
    "    PadlockArms\n",
    ")\n",
    "\n",
    "# the melting temperature params need to be preprocessed\n",
    "Tm_params = config[\"Tm_parameters\"][\"shared\"].copy()\n",
    "Tm_params.update(config[\"Tm_parameters\"][\"property_filter\"])\n",
    "Tm_params[\"nn_table\"] = getattr(mt, Tm_params[\"nn_table\"])\n",
    "Tm_params[\"tmm_table\"] = getattr(mt, Tm_params[\"tmm_table\"])\n",
    "Tm_params[\"imm_table\"] = getattr(mt, Tm_params[\"imm_table\"])\n",
    "Tm_params[\"de_table\"] = getattr(mt, Tm_params[\"de_table\"])\n",
    "\n",
    "Tm_chem_correction_param = config[\"Tm_chem_correction_param\"][\"shared\"].copy()\n",
    "Tm_chem_correction_param.update(config[\"Tm_chem_correction_param\"][\"property_filter\"])\n",
    "\n",
    "# initialize the filters clasees\n",
    "masked_sequences = MaskedSequences()\n",
    "gc_content = GCContent(GC_content_min=config[\"GC_content_min\"], GC_content_max=config[\"GC_content_max\"])\n",
    "melting_temperature = MeltingTemperatureNN(\n",
    "    Tm_min=config[\"Tm_min\"], \n",
    "    Tm_max=config[\"Tm_max\"], \n",
    "    Tm_parameters=Tm_params, \n",
    "    Tm_chem_correction_parameters=Tm_chem_correction_param\n",
    ")\n",
    "padlock_arms = PadlockArms(\n",
    "    min_arm_length=config[\"min_arm_length\"],\n",
    "    max_arm_Tm_dif=config[\"max_arm_Tm_dif\"],\n",
    "    arm_Tm_min=config[\"arm_Tm_min\"],\n",
    "    arm_Tm_max=config[\"arm_Tm_max\"],\n",
    "    Tm_parameters=Tm_params,\n",
    "    Tm_chem_correction_parameters=Tm_chem_correction_param,\n",
    ")\n",
    "# create the list of filters\n",
    "filters = [masked_sequences, gc_content, melting_temperature, padlock_arms]\n",
    "\n",
    "# initialize the property filter class\n",
    "property_filter = PropertyFilter(filters=filters, write_regions_with_insufficient_oligos=config[\"write_removed_genes\"])\n",
    "# filter the database\n",
    "oligo_database = property_filter.apply(oligo_database=oligo_database, n_jobs=config[\"n_jobs\"])\n",
    "# write the intermediate result in a file\n",
    "if config[\"write_intermediate_steps\"]:\n",
    "    file_database = oligo_database.write_database(filename=\"oligo_database_property_filter.txt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specificity filters\n",
    "\n",
    "In experiments using short oligos one of the main problem that can occur are off-target binding of the designed oligo sequences to undesired target regions. To avoid this problem we can decide to remove all the oligos that also align to regions outside the gene they belong to.\n",
    "\n",
    "The classes in the subpackage `oligo_speificity_filters` detect these oligos using alignment methods such as Blast and Bowtie and remove them from the database. The currently implemeted classes are: `ExactMatches`, `Blastn`, `Bowtie`, `Bowtie2`, `BowtieSeedRegion`. Look at the documentation for detailed information. Those filters are structured in the same way as the property filters. A second class `SpecificityFilter` takes a list of all the filters we want to apply, and applies them sequentially to the `OligoDatabase.database`.  \n",
    "*Note: the filters are applied in the order they are given as input. Hence, filter with fast computations should be listed first, i.e. apply exact match filter before Blastn filter, to reduce runtime.*\n",
    "\n",
    "In addition, alignement methods need a reference fasta file to detect the off-target regions. The `CustomGenomicRegionGenerator` class provides the possibility to generate this reference region as shown proviously. Once the fasta file has been created the class `ReferenceDatabase` stores the path, additional information and can extract regions we are intered in from the fasta file.\n",
    "\n",
    "*Note: it is possible to apply a set of specificity filters with a reference file and a second set with a different reference file.*\n",
    "\n",
    "For our pipeline, we will use `ExactMatches`, `Blastn`, `BowtieSeedRegion`. For the `BowtieSeedRegion` filter we need to generate the oligo seed region with `LigationRegionCreation` (look at the documentation to understand what seed region means). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# reads processed: 2678\n",
      "# reads with at least one alignment: 2678 (100.00%)\n",
      "# reads that failed to align: 0 (0.00%)\n",
      "Reported 87163 alignments\n",
      "# reads processed: 136\n",
      "# reads with at least one alignment: 136 (100.00%)\n",
      "# reads that failed to align: 0 (0.00%)\n",
      "Reported 2873 alignments\n",
      "# reads processed: 2117\n",
      "# reads with at least one alignment: 2117 (100.00%)\n",
      "# reads that failed to align: 0 (0.00%)\n",
      "Reported 87883 alignments\n",
      "# reads processed: 575\n",
      "# reads with at least one alignment: 575 (100.00%)\n",
      "# reads that failed to align: 0 (0.00%)\n",
      "Reported 15202 alignments\n",
      "# reads processed: 369\n",
      "# reads with at least one alignment: 369 (100.00%)\n",
      "# reads that failed to align: 0 (0.00%)\n",
      "Reported 21850 alignments\n"
     ]
    }
   ],
   "source": [
    "from oligo_designer_toolsuite.database import ReferenceDatabase\n",
    "from oligo_designer_toolsuite.oligo_specificity_filter import (\n",
    "    SpecificityFilter,\n",
    "    ExactMatches,\n",
    "    LigationRegionCreation,\n",
    "    BowtieSeedRegion,\n",
    "    Blastn,\n",
    ")\n",
    "\n",
    "dir_specificity = os.path.join(dir_output, \"specificity_temporary\") # folder where the temporary files will be written\n",
    "\n",
    "\n",
    "reference = ReferenceDatabase(\n",
    "    file_fasta = file_transcriptome,\n",
    "    files_source = region_generator_custom.files_source,\n",
    "    species = region_generator_custom.species,\n",
    "    annotation_release = region_generator_custom.annotation_release,\n",
    "    genome_assembly = region_generator_custom.genome_assembly,\n",
    "    dir_output=dir_output\n",
    "    )\n",
    "\n",
    "# intialize the filter classes\n",
    "exact_mathces = ExactMatches(dir_specificity=dir_specificity)\n",
    "seed_ligation = LigationRegionCreation(ligation_region_size=config[\"ligation_region_size\"])\n",
    "seed_region = BowtieSeedRegion(dir_specificity=dir_specificity, seed_region_creation=seed_ligation)\n",
    "blastn = Blastn(\n",
    "    dir_specificity=dir_specificity, \n",
    "    word_size=config[\"word_size\"],\n",
    "    percent_identity=config[\"percent_identity\"],\n",
    "    coverage=config[\"coverage\"],\n",
    "    strand=config[\"strand\"],\n",
    ")\n",
    "filters = [exact_mathces, seed_region, blastn]\n",
    "\n",
    "# initialize the specificity filter class\n",
    "specificity_filter = SpecificityFilter(filters=filters, write_regions_with_insufficient_oligos=config[\"write_removed_genes\"])\n",
    "# filte r the database\n",
    "oligo_database = specificity_filter.apply(oligo_database=oligo_database, reference_database=reference, n_jobs=config[\"n_jobs\"])\n",
    "# write the intermediate result\n",
    "if config[\"write_intermediate_steps\"]:\n",
    "    file_database = oligo_database.write_database(filename=\"oligo_database_specificity_filter.txt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oligoset generation\n",
    "\n",
    "In the next step of the pipeline the oligos will be choosen according to their theoretical efficiency in the experiment scope (e.g. how well they bind to the target in the DNA). Each oligo will receive a score computed by a class that inherits from `OligoScoringBase`. Later, the sequences will be organized in sets and a class inheriting from `SetScoringBase` will give a general efficiency score to the set. At the end the best sets will be selected and scored.\n",
    "\n",
    "It is required that the each array of sequences contains oligos that do not overlap. In fact, if two oligos were overlapping, they would compete to bind to the same section of DNA and their efficiency would drop significantly. Therefore, we only consider sets of non-overlapping sequences.\n",
    "\n",
    "The class `OligosetGenerator` takes the scoring strategies and tries to find, among all the feasible non-overlapping sets of oligos, the sets with the best efficiency scores. These sets will be save in a pandas DataFrame with the following structure:\n",
    "\n",
    "\n",
    " oligoset_id | oligo_0  | oligo_1  | oligo_2  |  ...  | oligo_n  | set_score_1 | set_score_2 |  ...  \n",
    "------------ | -------- | -------- | -------- | ----- | -------- | ----------- | ----------- | ------:\n",
    " 0           | AGRN_184 | AGRN_133 | AGRN_832 |  ...  | AGRN_706 | 0.3445      | 1.2332      |  ...  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oligo_designer_toolsuite.oligo_efficiency import(\n",
    "    PadlockOligoScoring,\n",
    "    PadlockSetScoring,\n",
    ")\n",
    "from oligo_designer_toolsuite.oligo_selection import OligosetGenerator, padlock_heuristic_selection\n",
    "\n",
    "# initialize the scoring classes\n",
    "oligos_scoring = PadlockOligoScoring(\n",
    "    Tm_min=config[\"Tm_min\"],\n",
    "    Tm_opt=config[\"Tm_opt\"],\n",
    "    Tm_max=config[\"Tm_max\"],\n",
    "    GC_content_min=config[\"GC_content_min\"],\n",
    "    GC_content_opt=config[\"GC_content_opt\"],\n",
    "    GC_content_max=config[\"GC_content_max\"],\n",
    "    Tm_weight=config[\"Tm_weight\"],\n",
    "    GC_weight=config[\"GC_weight\"],\n",
    ")\n",
    "set_scoring = PadlockSetScoring()\n",
    "\n",
    "# initialize the oligoset generator class\n",
    "oligoset_generator = OligosetGenerator(\n",
    "    oligoset_size=config[\"oligoset_size\"], \n",
    "    min_oligoset_size=config[\"min_oligoset_size\"],\n",
    "    oligos_scoring=oligos_scoring,\n",
    "    set_scoring=set_scoring,\n",
    "    heurustic_selection=padlock_heuristic_selection,\n",
    "    write_regions_with_insufficient_oligos=config[\"write_removed_genes\"]\n",
    ")\n",
    "\n",
    "# generate the oligoset\n",
    "oligo_database = oligoset_generator.apply(oligo_database=oligo_database, n_sets=config[\"n_sets\"], n_jobs=config[\"n_jobs\"])\n",
    "# write the intermediate result\n",
    "if config[\"write_intermediate_steps\"]:\n",
    "    file_database = oligo_database.write_database(filename=\"oligo_database_oligosets.txt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last step\n",
    "\n",
    "Once the best oligosets are generated each experiment design might require (or not) an addtional step. In the case of the Padlock oligo designer the last step consists in designing the final padlock probe sequences containing the padlock probe and detection probe sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oligo_designer_toolsuite.sequence_design import PadlockSequence\n",
    "\n",
    "# preprocessing of themelting temperature parameters\n",
    "Tm_params = config[\"Tm_parameters\"][\"shared\"].copy()\n",
    "Tm_params.update(config[\"Tm_parameters\"][\"detection_oligo\"])\n",
    "Tm_params[\"nn_table\"] = getattr(mt, Tm_params[\"nn_table\"])\n",
    "Tm_params[\"tmm_table\"] = getattr(mt, Tm_params[\"tmm_table\"])\n",
    "Tm_params[\"imm_table\"] = getattr(mt, Tm_params[\"imm_table\"])\n",
    "Tm_params[\"de_table\"] = getattr(mt, Tm_params[\"de_table\"])\n",
    "\n",
    "Tm_chem_correction_parameters = config[\"Tm_chem_correction_param\"][\"shared\"].copy()\n",
    "Tm_chem_correction_parameters.update(config[\"Tm_chem_correction_param\"][\"detection_oligo\"])\n",
    "\n",
    "# initilize the padlock sequence designer class\n",
    "padlock_sequence = PadlockSequence(\n",
    "    detect_oligo_length_min=config[\"detect_oligo_length_min\"],\n",
    "    detect_oligo_length_max=config[\"detect_oligo_length_max\"],\n",
    "    detect_oligo_Tm_opt=config[\"detect_oligo_Tm_opt\"],\n",
    "    Tm_parameters=Tm_params,\n",
    "    Tm_chem_correction_parameters=Tm_chem_correction_parameters,\n",
    "    dir_output = dir_output\n",
    ")\n",
    "# generate the padlock sequence\n",
    "padlock_sequence.design_final_padlock_sequence(oligo_database=oligo_database)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16 (main, Jan 11 2023, 10:02:19) \n[Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "91ae2b822b2c63763376465ee82482a220c569ab63f255cee6acbc07ca1cebfb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
