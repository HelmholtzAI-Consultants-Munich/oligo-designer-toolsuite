{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Padlock Probe Designer\n",
    "\n",
    "This notebook implements a pipeline to designe Padlock probes (short oligos) using the `oligo_designer_toolsuite` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the necassary pakages exept from the oligo_designer_toolsuite\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "\n",
    "import yaml\n",
    "from Bio.SeqUtils import MeltingTemp as mt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the parameters\n",
    "\n",
    "First, we need to define the parameters we want to use to generate the Padlock probes. \n",
    "A possible way to define all the parameters, that is flexible and reusable, is to use a configuration file. \n",
    "For this tutorial we will use the YAML file `padlock_probe_designer_custom.yaml`, which uses a custom gene annotation (GTF file - GFF3 not supported) and genome sequence (fasta file). As an example, we use human gene annotation and genome sequence of chromsome 16. Check out the config file to understand which parameters are required and how the configuration file is structured.\n",
    "If you want to use NCBI or Ensembl gene annotation and genome sequence with automatic file download from their servers, please check out the YAML files `padlock_probe_designer_ncbi.yaml` and `padlock_probe_designer_ensembl.yaml`.\n",
    "\n",
    "Once the configuration file has been set up we have to read its content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"./configs/padlock_probe_designer_custom.yaml\"\n",
    "# config_file = \"./configs/padlock_probe_designer_ncbi.yaml\" # NCBI config\n",
    "# config_file = \"./configs/padlock_probe_designer_ensemble.yaml\" # Ensemble config\n",
    "with open(config_file, 'r') as yaml_file:\n",
    "    config = yaml.safe_load(yaml_file)\n",
    "dir_output = os.path.join(os.path.dirname(os.getcwd()), config[\"dir_output\"]) # create the complete path for the output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/cw/PycharmProjects/oligo-designer-toolsuite_merfish/output_tutorial'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Genomic Regions for the Oligo and Reference Database\n",
    "\n",
    "Now we can start to build the pipeline. We start with generating the fasta file used as basis for the oligo database and reference database for the alignement methods. *Note: you can use different fasta files to create the oligo and reference database.* From the provided genome annotation (fasta file), specific regions can be extracted. In particular, it is possible to use: \n",
    "\n",
    "- the whole genome\n",
    "- the transcriptome\n",
    "- the coding sequence (CDS)\n",
    "\n",
    "To create specific regions, we need a `CustomGenomicRegionGenerator`, or a class that inherits form it (e.g. `NcbiGenomicRegionGenerator` and `EnsemblGenomicRegionGenerator`) and call the method `generate_transcript_reduced_representation()` to extract the transcriptome in a reduced representation form from the given files. These classes differ on how the the fasta and the GTF (GFF3 not supported) files used are obtained. The first one uses local files while the others dowload them respectively form the NCBI or Ensambl ftp server. *Note: that the GTF file must contain coordinate as well as transcript ID and exon number infomration to generate a transcriptome or coding sequence.* In the output fasta file, the header of each sequence must start with '>' and contain the following information: \n",
    "region_id, additional_information and coordinates (chrom, start, end, strand)\n",
    "\n",
    "Input Format (per sequence):  \n",
    "`>region_id::additional information::chromosome:start-end(strand)`  \n",
    "`sequence`\n",
    "\n",
    "Example:  \n",
    "`>ASR1::transcrip_id=XM456,exon_number=5::16:54552-54786(+)`  \n",
    "`AGTTGACAGACCCCAGATTAAAGTGTGTCGCGCAACAC` \n",
    "\n",
    "To use NCBi or Ensembl files, comment in the respective config files in the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oligo_designer_toolsuite.database import CustomGenomicRegionGenerator, NcbiGenomicRegionGenerator, EnsemblGenomicRegionGenerator\n",
    "\n",
    "# If the custom config file is selected\n",
    "if config[\"source\"] == \"custom\":\n",
    "    region_generator_custom = CustomGenomicRegionGenerator(\n",
    "        annotation_file=config[\"file_annotation\"], \n",
    "        sequence_file=config[\"file_sequence\"], \n",
    "        files_source=config[\"files_source\"], \n",
    "        species=config[\"species\"], \n",
    "        annotation_release=config[\"annotation_release\"], \n",
    "        genome_assembly=config[\"genome_assembly\"],\n",
    "        dir_output=dir_output\n",
    "    )\n",
    "# If the Ncbi config file is selected\n",
    "elif config[\"source\"] == \"ncbi\":\n",
    "    region_generator = NcbiGenomicRegionGenerator(\n",
    "        taxon=config[\"taxon\"],\n",
    "        species=config[\"species\"], \n",
    "        annotation_release=config[\"annotation_release\"], \n",
    "        dir_output=dir_output\n",
    "    )\n",
    "# If the Ensembl config file is generated\n",
    "elif config[\"source\"] == \"ensembl\":\n",
    "    region_generator = EnsemblGenomicRegionGenerator(\n",
    "        species=config[\"species\"], \n",
    "        annotation_release=config[\"annotation_release\"], \n",
    "        dir_output=dir_output\n",
    "    )\n",
    "\n",
    "file_transcriptome = region_generator_custom.generate_transcript_reduced_representation(include_exon_junctions=True, exon_junction_size=2*config[\"oligo_length_max\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/cw/PycharmProjects/oligo-designer-toolsuite_merfish/output_tutorial/annotation/transcriptome_source_NCBI_species_Homo_sapiens_annotation_release_110_genome_assemly_GRCh38_incl_exonjunctions_of_size_90.fna'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_transcriptome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oligo sequences generation\n",
    "\n",
    "\n",
    "Next we will generate all the possible oligos with length between the maximum and minimum value given belonging to the genes defined in the config file. For this we intialize the class ``OligoDatabase`` and use the meothod ``create_database()``.  \n",
    "The ``OligoDatabase`` requires a fasta file as input. This fasta file can be created using a ``GenomicRegionGenerator`` (see code in cell above) or a custom fasta file can be provided. The input fasta file needs a header for each sequence, which must start with '>' and contain the following information: \n",
    "region_id, additional_information and coordinates (chrom, start, end, strand), where the region_id is compulsory and the other fileds are opional.\n",
    "\n",
    "Input Format (per sequence):  \n",
    "`>region_id::additional information::chromosome:start-end(strand)`  \n",
    "`sequence`\n",
    "\n",
    "Example:  \n",
    "`>ASR1::transcrip_id=XM456,exon_number=5::16:54552-54786(+)`  \n",
    "`AGTTGACAGACCCCAGATTAAAGTGTGTCGCGCAACAC`  \n",
    "or   \n",
    "`>ASR1`  \n",
    "`AGTTGACAGACCCCAGATTAAAGTGTGTCGCGCAACAC`\n",
    "\n",
    "The generated probes will be saved in a nested dicionary with the following structure: \n",
    "\n",
    "``[gene][oligo_id][oligo_features]``\n",
    "\n",
    "*Note: if you already have a stored database you can load it into an OligoDatabase object by using the ``load_oligo_database()`` function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from oligo_designer_toolsuite.database import OligoDatabase\n",
    "\n",
    "# define the database class\n",
    "oligo_database = OligoDatabase(\n",
    "    file_fasta = file_transcriptome,\n",
    "    oligo_length_min = config[\"oligo_length_min\"],\n",
    "    oligo_length_max = config[\"oligo_length_max\"],\n",
    "    min_oligos_per_region = config[\"min_oligos_per_gene\"],\n",
    "    files_source = region_generator_custom.files_source,\n",
    "    species = region_generator_custom.species,\n",
    "    annotation_release = region_generator_custom.annotation_release,\n",
    "    genome_assembly = region_generator_custom.genome_assembly,\n",
    "    n_jobs = 2,\n",
    "    dir_output=dir_output\n",
    ")\n",
    "\n",
    "# read the genes file\n",
    "if config[\"file_genes\"] is None:\n",
    "    warnings.warn(\n",
    "        \"No file containing the genes was provided, all the genes are ussed to generate the probes. This chioce can use a lot of resources.\"\n",
    "    )\n",
    "    genes = None\n",
    "else:\n",
    "    with open(config[\"file_genes\"]) as handle:\n",
    "        lines = handle.readlines()\n",
    "        genes = [line.rstrip() for line in lines]\n",
    "\n",
    "# generate the oligo sequences from gene transcripts\n",
    "oligo_database.create_database(region_ids=genes)\n",
    "\n",
    "# alternative: load database from file\n",
    "# oligo_database.load_oligo_database(file_database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bc25mer_1', 'bc25mer_2', 'bc25mer_3', 'bc25mer_4', 'bc25mer_5']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(oligo_database.database.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bc25mer_1': {'bc25mer_1_None:Unknown-Unknown(None)': {'sequence': Seq('TATGAGGACGAATCTCCCGCTTATA'), 'chromosome': None, 'start': ['Unknown'], 'end': ['Unknown'], 'strand': None, 'length': 25, 'additional_information_fasta': [[]]}}}\n"
     ]
    }
   ],
   "source": [
    "gene = list(oligo_database.database.keys())[0]\n",
    "oligo_id = list(oligo_database.database[gene].keys())[0]\n",
    "\n",
    "sample_oligos_DB = {gene: {oligo_id: oligo_database.database[gene][oligo_id]}}\n",
    "print(sample_oligos_DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from oligo_designer_toolsuite.database import OligoDatabase\n",
    "file_transcriptome = \"/home/cw/PycharmProjects/oligo-designer-toolsuite_merfish/oligo_designer_toolsuite/experiment_specific/oligos_creation/bc25mer.240k.fasta\"\n",
    "# define the database class\n",
    "oligo_database = OligoDatabase(\n",
    "    file_fasta = file_transcriptome,\n",
    "    oligo_length_min = 20,\n",
    "    oligo_length_max = 30,\n",
    "    min_oligos_per_region = 1,\n",
    "    files_source = \"bc25mer\",\n",
    "    species = \"None\",\n",
    "    annotation_release = \"None\",\n",
    "    genome_assembly = \"None\",\n",
    "    n_jobs = 2,\n",
    "    dir_output=\"/home/cw/PycharmProjects/oligo-designer-toolsuite_merfish/oligo_designer_toolsuite/experiment_specific\"\n",
    ")\n",
    "\n",
    "# read the genes file\n",
    "if config[\"file_genes\"] is None:\n",
    "    warnings.warn(\n",
    "        \"No file containing the genes was provided, all the genes are ussed to generate the probes. This chioce can use a lot of resources.\"\n",
    "    )\n",
    "    genes = None\n",
    "else:\n",
    "    with open(config[\"file_genes\"]) as handle:\n",
    "        lines = handle.readlines()\n",
    "        genes = [line.rstrip() for line in lines]\n",
    "        \n",
    "# generate the oligo sequences from gene transcripts\n",
    "oligo_database.create_database(region_ids=genes)\n",
    "\n",
    "# alternative: load database from file\n",
    "\n",
    "#oligo_database.load_oligo_database(file_database)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AARS1', 'DECR2', 'FAM234A', 'RHBDF1', 'WASIR2']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'oligo_database' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43moligo_database\u001b[49m\u001b[38;5;241m.\u001b[39mload_oligo_database(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/cw/PycharmProjects/oligo-designer-toolsuite_merfish/tutorials/data/oligos_creation/oligo_DB_human_GRCh38.p14_NCBI_release_current_transcripts.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'oligo_database' is not defined"
     ]
    }
   ],
   "source": [
    "oligo_database.load_oligo_database(\"/home/cw/PycharmProjects/oligo-designer-toolsuite_merfish/tutorials/data/oligos_creation/oligo_DB_human_GRCh38.p14_NCBI_release_current_transcripts.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary structure\n",
    "\n",
    "Here is an example of how the nested dictionary is structured for one oligo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AARS1': {'AARS1_16:70265624-70265662(-)': {'sequence': Seq('GAGACACTGCTTGGCTCCTCTATGACACCTATGGGTTT'), 'chromosome': '16', 'start': [70265624], 'end': [70265662], 'strand': '-', 'length': 38, 'additional_information_fasta': ['transcript_id=NM_001605.3,exon_number=10;transcript_id=XM_047433666.1,exon_number=10']}}}\n"
     ]
    }
   ],
   "source": [
    "gene = list(oligo_database.database.keys())[0]\n",
    "oligo_id = list(oligo_database.database[gene].keys())[0]\n",
    "\n",
    "sample_oligos_DB = {gene: {oligo_id: oligo_database.database[gene][oligo_id]}}\n",
    "print(sample_oligos_DB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and write\n",
    "\n",
    "The ``OligoDatabase`` class deals with everything that is related to the management of the database. In particular, beyond creatig the database, it can also read and write the oligo sequences in a **tsv** fromat. The methods `load_database()` and `write_database()`,  have exactly this purpose. It is also possible to write the sequences as a fasta file with the method ``write_fasta_from_database()``.\n",
    "\n",
    "This allows us to save the current state of the database during the pipeline and to retrive it form a previous stage if an error uccurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"write_intermediate_steps\"]:\n",
    "    file_database = oligo_database.write_database(filename=\"oligo_database_initial.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Property filters\n",
    "\n",
    "Once all the possible sequences are created, we apply a first filtering step based on the sequence properties (e.g. melting temperature or GC content). This is useful to reduce the amount of sequences we have to deal with in the next stages and discard all the sequences that are not suited for the experiment.\n",
    "\n",
    "Each property filter is a class that inherits from the Abstact Base Class `PropertyFilterBase` They have a method called `apply` that takes the `OligoDatabase.database` dictionary and returns it filtered. To make this process smooth and modular the wrapper class `PropertyFilter` allows to apply several filters one after the other. It takes as input a list of filter classes and an `OligoDatabase` object and applies sequentially all the filters and returns the final filterd version of the database. Additionally, all the necessary sequence features computed by the filters are stored in the `OligoDatabase.database` for possible later use. \n",
    "\n",
    "*Note: the filters are applied in the order they are given as input. Hence, filter with fast computations should be listed first, i.e. apply GC content filter before melting temperature filter, to reduce runtime.*\n",
    "\n",
    "To create new property filters follow the Abstact Base Class requirements in `PropertyFilterBase`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oligo_designer_toolsuite.oligo_property_filter import (\n",
    "    PropertyFilter,\n",
    "    MaskedSequences,\n",
    "    GCContent, \n",
    "    MeltingTemperatureNN, \n",
    "    PadlockArms\n",
    ")\n",
    "\n",
    "# the melting temperature params need to be preprocessed\n",
    "Tm_params = config[\"Tm_parameters\"][\"shared\"].copy()\n",
    "Tm_params.update(config[\"Tm_parameters\"][\"property_filter\"])\n",
    "Tm_params[\"nn_table\"] = getattr(mt, Tm_params[\"nn_table\"])\n",
    "Tm_params[\"tmm_table\"] = getattr(mt, Tm_params[\"tmm_table\"])\n",
    "Tm_params[\"imm_table\"] = getattr(mt, Tm_params[\"imm_table\"])\n",
    "Tm_params[\"de_table\"] = getattr(mt, Tm_params[\"de_table\"])\n",
    "\n",
    "Tm_chem_correction_param = config[\"Tm_chem_correction_param\"][\"shared\"].copy()\n",
    "Tm_chem_correction_param.update(config[\"Tm_chem_correction_param\"][\"property_filter\"])\n",
    "\n",
    "# initialize the filters clasees\n",
    "masked_sequences = MaskedSequences()\n",
    "gc_content = GCContent(GC_content_min=config[\"GC_content_min\"], GC_content_max=config[\"GC_content_max\"])\n",
    "melting_temperature = MeltingTemperatureNN(\n",
    "    Tm_min=config[\"Tm_min\"], \n",
    "    Tm_max=config[\"Tm_max\"], \n",
    "    Tm_parameters=Tm_params, \n",
    "    Tm_chem_correction_parameters=Tm_chem_correction_param\n",
    ")\n",
    "padlock_arms = PadlockArms(\n",
    "    min_arm_length=config[\"min_arm_length\"],\n",
    "    max_arm_Tm_dif=config[\"max_arm_Tm_dif\"],\n",
    "    arm_Tm_min=config[\"arm_Tm_min\"],\n",
    "    arm_Tm_max=config[\"arm_Tm_max\"],\n",
    "    Tm_parameters=Tm_params,\n",
    "    Tm_chem_correction_parameters=Tm_chem_correction_param,\n",
    ")\n",
    "# create the list of filters\n",
    "filters = [masked_sequences, gc_content, melting_temperature, padlock_arms]\n",
    "\n",
    "# initialize the property filter class\n",
    "property_filter = PropertyFilter(filters=filters, write_regions_with_insufficient_oligos=config[\"write_removed_genes\"])\n",
    "# filter the database\n",
    "oligo_database = property_filter.apply(oligo_database=oligo_database, n_jobs=config[\"n_jobs\"])\n",
    "# write the intermediate result in a file\n",
    "if config[\"write_intermediate_steps\"]:\n",
    "    file_database = oligo_database.write_database(filename=\"oligo_database_property_filter.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specificity filters\n",
    "\n",
    "In experiments using short oligos one of the main problem that can occur are off-target binding of the designed oligo sequences to undesired target regions. To avoid this problem we can decide to remove all the oligos that also align to regions outside the gene they belong to.\n",
    "\n",
    "The classes in the subpackage `oligo_speificity_filters` detect these oligos using alignment methods such as Blast and Bowtie and remove them from the database. The currently implemeted classes are: `ExactMatches`, `Blastn`, `Bowtie`, `Bowtie2`, `BowtieSeedRegion`. Look at the documentation for detailed information. Those filters are structured in the same way as the property filters. A second class `SpecificityFilter` takes a list of all the filters we want to apply, and applies them sequentially to the `OligoDatabase.database`.  \n",
    "*Note: the filters are applied in the order they are given as input. Hence, filter with fast computations should be listed first, i.e. apply exact match filter before Blastn filter, to reduce runtime.*\n",
    "\n",
    "In addition, alignement methods need a reference fasta file to detect the off-target regions. The `CustomGenomicRegionGenerator` class provides the possibility to generate this reference region as shown proviously. Once the fasta file has been created the class `ReferenceDatabase` stores the path, additional information and can extract regions we are intered in from the fasta file.\n",
    "\n",
    "*Note: it is possible to apply a set of specificity filters with a reference file and a second set with a different reference file.*\n",
    "\n",
    "For our pipeline, we will use `ExactMatches`, `Blastn`, `BowtieSeedRegion`. For the `BowtieSeedRegion` filter we need to generate the oligo seed region with `LigationRegionCreation` (look at the documentation to understand what seed region means)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/cw/PycharmProjects/oligo-designer-toolsuite_merfish/output_tutorial/annotation/transcriptome_source_NCBI_species_Homo_sapiens_annotation_release_110_genome_assemly_GRCh38_incl_exonjunctions_of_size_90.fna'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'/home/cw/PycharmProjects/oligo-designer-toolsuite_merfish/output_tutorial/annotation/transcriptome_source_NCBI_species_Homo_sapiens_annotation_release_110_genome_assemly_GRCh38_incl_exonjunctions_of_size_90.fna'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'/home/cw/PycharmProjects/oligo-designer-toolsuite_merfish/output_tutorial/annotation/transcriptome_source_NCBI_species_Homo_sapiens_annotation_release_110_genome_assemly_GRCh38_incl_exonjunctions_of_size_90.fna'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_transcriptome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "with open(file_transcriptome, \"r\") as handle:\n",
    "    fasta = SeqIO.parse(handle, \"fasta\")\n",
    "    print(any(fasta)) # False when `fasta` is empty, i.e. wasn't a FASTA file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bin/sh: bowtie-build: command not found\n",
      "/bin/sh: bowtie: command not found\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/anna/Desktop/Project/oligo-designer-toolsuite/output/specificity_temporary/bowtie/bowtie_AARS1.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m specificity_filter \u001b[39m=\u001b[39m SpecificityFilter(filters\u001b[39m=\u001b[39mfilters, write_regions_with_insufficient_oligos\u001b[39m=\u001b[39mconfig[\u001b[39m\"\u001b[39m\u001b[39mwrite_removed_genes\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     37\u001b[0m \u001b[39m# filte r the database\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m oligo_database \u001b[39m=\u001b[39m specificity_filter\u001b[39m.\u001b[39;49mapply(oligo_database\u001b[39m=\u001b[39;49moligo_database, reference_database\u001b[39m=\u001b[39;49mreference, n_jobs\u001b[39m=\u001b[39;49mconfig[\u001b[39m\"\u001b[39;49m\u001b[39mn_jobs\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m     39\u001b[0m \u001b[39m# write the intermediate result\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39mif\u001b[39;00m config[\u001b[39m\"\u001b[39m\u001b[39mwrite_intermediate_steps\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/Desktop/Project/oligo-designer-toolsuite/oligo_designer_toolsuite/oligo_specificity_filter/_specificity_filters.py:52\u001b[0m, in \u001b[0;36mSpecificityFilter.apply\u001b[0;34m(self, oligo_database, reference_database, n_jobs)\u001b[0m\n\u001b[1;32m     50\u001b[0m database \u001b[39m=\u001b[39m oligo_database\u001b[39m.\u001b[39mdatabase\n\u001b[1;32m     51\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39mfilter\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilters:\n\u001b[0;32m---> 52\u001b[0m     database \u001b[39m=\u001b[39m \u001b[39mfilter\u001b[39;49m\u001b[39m.\u001b[39;49mapply(\n\u001b[1;32m     53\u001b[0m         database, reference_database\u001b[39m.\u001b[39;49mfile_fasta, n_jobs\n\u001b[1;32m     54\u001b[0m     )\n\u001b[1;32m     56\u001b[0m oligo_database\u001b[39m.\u001b[39mdatabase \u001b[39m=\u001b[39m database\n\u001b[1;32m     57\u001b[0m oligo_database\u001b[39m.\u001b[39mremove_regions_with_insufficient_oligos(\n\u001b[1;32m     58\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mSpecificity filter\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite_regions_with_insufficient_oligos\n\u001b[1;32m     59\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/Project/oligo-designer-toolsuite/oligo_designer_toolsuite/oligo_specificity_filter/_filter_seed_region.py:85\u001b[0m, in \u001b[0;36mBowtieSeedRegion.apply\u001b[0;34m(self, database, file_reference_DB, n_jobs)\u001b[0m\n\u001b[1;32m     83\u001b[0m oligo_DB_seed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extract_seed_regions(database)\n\u001b[1;32m     84\u001b[0m regions \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(oligo_DB_seed\u001b[39m.\u001b[39mkeys())\n\u001b[0;32m---> 85\u001b[0m filtered_oligo_DBs \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49mn_jobs)(\n\u001b[1;32m     86\u001b[0m     delayed(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_bowtie_seed_region)(\n\u001b[1;32m     87\u001b[0m         oligo_DB_seed[region], database[region], region, index_name\n\u001b[1;32m     88\u001b[0m     )\n\u001b[1;32m     89\u001b[0m     \u001b[39mfor\u001b[39;49;00m region \u001b[39min\u001b[39;49;00m regions\n\u001b[1;32m     90\u001b[0m )\n\u001b[1;32m     92\u001b[0m \u001b[39m# reconstruct the oligos_DB\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[39mfor\u001b[39;00m region, filtered_oligo_DB \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(regions, filtered_oligo_DBs):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/joblib/parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/Desktop/Project/oligo-designer-toolsuite/oligo_designer_toolsuite/oligo_specificity_filter/_filter_seed_region.py:127\u001b[0m, in \u001b[0;36mBowtieSeedRegion._run_bowtie_seed_region\u001b[0;34m(self, database_region_seed, gene_DB, region, index_name)\u001b[0m\n\u001b[1;32m    124\u001b[0m process \u001b[39m=\u001b[39m Popen(command, shell\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, cwd\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdir_seed_region)\u001b[39m.\u001b[39mwait()\n\u001b[1;32m    126\u001b[0m \u001b[39m# read the results of the bowtie search\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m bowtie_results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_bowtie_output(file_bowtie_gene)\n\u001b[1;32m    128\u001b[0m \u001b[39m# filter the DB based on the bowtie results\u001b[39;00m\n\u001b[1;32m    129\u001b[0m matching_oligos \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_find_matching_oligos(bowtie_results)\n",
      "File \u001b[0;32m~/Desktop/Project/oligo-designer-toolsuite/oligo_designer_toolsuite/oligo_specificity_filter/_filter_bowtie.py:153\u001b[0m, in \u001b[0;36mBowtie._read_bowtie_output\u001b[0;34m(self, file_bowtie_gene)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_bowtie_output\u001b[39m(\u001b[39mself\u001b[39m, file_bowtie_gene):\n\u001b[1;32m    152\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load the output of the bowtie alignment search into a DataFrame and process the results.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     bowtie_results \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\n\u001b[1;32m    154\u001b[0m         file_bowtie_gene,\n\u001b[1;32m    155\u001b[0m         header\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    156\u001b[0m         sep\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\\t\u001b[39;49;00m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    157\u001b[0m         low_memory\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    158\u001b[0m         names\u001b[39m=\u001b[39;49m[\n\u001b[1;32m    159\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mquery\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    160\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mstrand\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    161\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mreference\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    162\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mref_start\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    163\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mquery_sequence\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    164\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mread_quality\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    165\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mnum_instances\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    166\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mmismatch_positions\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    167\u001b[0m         ],\n\u001b[1;32m    168\u001b[0m         engine\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mc\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    169\u001b[0m         dtype\u001b[39m=\u001b[39;49m{\n\u001b[1;32m    170\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mquery\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mstr\u001b[39;49m,\n\u001b[1;32m    171\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mstrand\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mstr\u001b[39;49m,\n\u001b[1;32m    172\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mreference\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mstr\u001b[39;49m,\n\u001b[1;32m    173\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mref_start\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mint\u001b[39;49m,\n\u001b[1;32m    174\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mquery_sequence\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mstr\u001b[39;49m,\n\u001b[1;32m    175\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mread_quality\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mstr\u001b[39;49m,\n\u001b[1;32m    176\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mnum_instances\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mint\u001b[39;49m,\n\u001b[1;32m    177\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mmismatch_positions\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mstr\u001b[39;49m,\n\u001b[1;32m    178\u001b[0m         },\n\u001b[1;32m    179\u001b[0m     )\n\u001b[1;32m    180\u001b[0m     \u001b[39m# return the real matches, that is the ones not belonging to the same region of the query oligo\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     bowtie_results[\u001b[39m\"\u001b[39m\u001b[39mquery_gene_id\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m bowtie_results[\u001b[39m\"\u001b[39m\u001b[39mquery\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mstr[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1736\u001b[0m     f,\n\u001b[1;32m   1737\u001b[0m     mode,\n\u001b[1;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1744\u001b[0m )\n\u001b[1;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/anna/Desktop/Project/oligo-designer-toolsuite/output/specificity_temporary/bowtie/bowtie_AARS1.txt'"
     ]
    }
   ],
   "source": [
    "from oligo_designer_toolsuite.database import ReferenceDatabase\n",
    "from oligo_designer_toolsuite.oligo_specificity_filter import (\n",
    "    SpecificityFilter,\n",
    "    ExactMatches,\n",
    "    LigationRegionCreation,\n",
    "    BowtieSeedRegion,\n",
    "    Blastn,\n",
    ")\n",
    "\n",
    "dir_specificity = os.path.join(dir_output, \"specificity_temporary\") # folder where the temporary files will be written\n",
    "\n",
    "\n",
    "reference = ReferenceDatabase(\n",
    "    file_fasta = file_transcriptome,\n",
    "    files_source = region_generator_custom.files_source,\n",
    "    species = region_generator_custom.species,\n",
    "    annotation_release = region_generator_custom.annotation_release,\n",
    "    genome_assembly = region_generator_custom.genome_assembly,\n",
    "    dir_output=dir_output\n",
    "    )\n",
    "\n",
    "# intialize the filter classes\n",
    "exact_mathces = ExactMatches(dir_specificity=dir_specificity)\n",
    "seed_ligation = LigationRegionCreation(ligation_region_size=config[\"ligation_region_size\"])\n",
    "seed_region = BowtieSeedRegion(dir_specificity=dir_specificity, seed_region_creation=seed_ligation)\n",
    "blastn = Blastn(\n",
    "    dir_specificity=dir_specificity, \n",
    "    word_size=config[\"word_size\"],\n",
    "    percent_identity=config[\"percent_identity\"],\n",
    "    coverage=config[\"coverage\"],\n",
    "    strand=config[\"strand\"],\n",
    ")\n",
    "filters = [exact_mathces, seed_region, blastn]\n",
    "\n",
    "# initialize the specificity filter class\n",
    "specificity_filter = SpecificityFilter(filters=filters, write_regions_with_insufficient_oligos=config[\"write_removed_genes\"])\n",
    "# filte r the database\n",
    "oligo_database = specificity_filter.apply(oligo_database=oligo_database, reference_database=reference, n_jobs=config[\"n_jobs\"])\n",
    "# write the intermediate result\n",
    "if config[\"write_intermediate_steps\"]:\n",
    "    file_database = oligo_database.write_database(filename=\"oligo_database_specificity_filter.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oligoset generation\n",
    "\n",
    "In the next step of the pipeline the oligos will be choosen according to their theoretical efficiency in the experiment scope (e.g. how well they bind to the target in the DNA). Each oligo will receive a score computed by a class that inherits from `OligoScoringBase`. Later, the sequences will be organized in sets and a class inheriting from `SetScoringBase` will give a general efficiency score to the set. At the end the best sets will be selected and scored.\n",
    "\n",
    "It is required that the each array of sequences contains oligos that do not overlap. In fact, if two oligos were overlapping, they would compete to bind to the same section of DNA and their efficiency would drop significantly. Therefore, we only consider sets of non-overlapping sequences.\n",
    "\n",
    "The class `OligosetGenerator` takes the scoring strategies and tries to find, among all the feasible non-overlapping sets of oligos, the sets with the best efficiency scores. These sets will be save in a pandas DataFrame with the following structure:\n",
    "\n",
    "\n",
    " oligoset_id | oligo_0  | oligo_1  | oligo_2  |  ...  | oligo_n  | set_score_1 | set_score_2 |  ...  \n",
    "------------ | -------- | -------- | -------- | ----- | -------- | ----------- | ----------- | ------:\n",
    " 0           | AGRN_184 | AGRN_133 | AGRN_832 |  ...  | AGRN_706 | 0.3445      | 1.2332      |  ...  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oligo_designer_toolsuite.oligo_efficiency import(\n",
    "    PadlockOligoScoring,\n",
    "    PadlockSetScoring,\n",
    ")\n",
    "from oligo_designer_toolsuite.oligo_selection import OligosetGenerator, padlock_heuristic_selection\n",
    "\n",
    "# initialize the scoring classes\n",
    "oligos_scoring = PadlockOligoScoring(\n",
    "    Tm_min=config[\"Tm_min\"],\n",
    "    Tm_opt=config[\"Tm_opt\"],\n",
    "    Tm_max=config[\"Tm_max\"],\n",
    "    GC_content_min=config[\"GC_content_min\"],\n",
    "    GC_content_opt=config[\"GC_content_opt\"],\n",
    "    GC_content_max=config[\"GC_content_max\"],\n",
    "    Tm_weight=config[\"Tm_weight\"],\n",
    "    GC_weight=config[\"GC_weight\"],\n",
    ")\n",
    "set_scoring = PadlockSetScoring()\n",
    "\n",
    "# initialize the oligoset generator class\n",
    "oligoset_generator = OligosetGenerator(\n",
    "    oligoset_size=config[\"oligoset_size\"], \n",
    "    min_oligoset_size=config[\"min_oligoset_size\"],\n",
    "    oligos_scoring=oligos_scoring,\n",
    "    set_scoring=set_scoring,\n",
    "    heurustic_selection=padlock_heuristic_selection,\n",
    "    write_regions_with_insufficient_oligos=config[\"write_removed_genes\"]\n",
    ")\n",
    "\n",
    "# generate the oligoset\n",
    "oligo_database = oligoset_generator.apply(oligo_database=oligo_database, n_sets=config[\"n_sets\"], n_jobs=config[\"n_jobs\"])\n",
    "# write the intermediate result\n",
    "if config[\"write_intermediate_steps\"]:\n",
    "    file_database = oligo_database.write_database(filename=\"oligo_database_oligosets.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last step\n",
    "\n",
    "Once the best oligosets are generated each experiment design might require (or not) an addtional step. In the case of the Padlock oligo designer the last step consists in designing the final padlock probe sequences containing the padlock probe and detection probe sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oligo_designer_toolsuite.sequence_design import PadlockSequence\n",
    "\n",
    "# preprocessing of themelting temperature parameters\n",
    "Tm_params = config[\"Tm_parameters\"][\"shared\"].copy()\n",
    "Tm_params.update(config[\"Tm_parameters\"][\"detection_oligo\"])\n",
    "Tm_params[\"nn_table\"] = getattr(mt, Tm_params[\"nn_table\"])\n",
    "Tm_params[\"tmm_table\"] = getattr(mt, Tm_params[\"tmm_table\"])\n",
    "Tm_params[\"imm_table\"] = getattr(mt, Tm_params[\"imm_table\"])\n",
    "Tm_params[\"de_table\"] = getattr(mt, Tm_params[\"de_table\"])\n",
    "\n",
    "Tm_chem_correction_parameters = config[\"Tm_chem_correction_param\"][\"shared\"].copy()\n",
    "Tm_chem_correction_parameters.update(config[\"Tm_chem_correction_param\"][\"detection_oligo\"])\n",
    "\n",
    "# initilize the padlock sequence designer class\n",
    "padlock_sequence = PadlockSequence(\n",
    "    detect_oligo_length_min=config[\"detect_oligo_length_min\"],\n",
    "    detect_oligo_length_max=config[\"detect_oligo_length_max\"],\n",
    "    detect_oligo_Tm_opt=config[\"detect_oligo_Tm_opt\"],\n",
    "    Tm_parameters=Tm_params,\n",
    "    Tm_chem_correction_parameters=Tm_chem_correction_parameters,\n",
    "    dir_output = dir_output\n",
    ")\n",
    "# generate the padlock sequence\n",
    "padlock_sequence.design_final_padlock_sequence(oligo_database=oligo_database)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "1615ef6491af5e87b9afff9dac6dddb07d1479905b03b1763ba4488454196f77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
