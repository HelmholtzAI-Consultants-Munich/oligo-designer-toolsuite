{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Build a Custom Oligo Design Pipeline?\n",
    "\n",
    "The Oligo Designer Toolsuite is a collection of modules that provide basic functionalities for custom oligo design pipelines within a flexible Python framework. \n",
    "All modules have a common underlying data structure and a standardized API, which allows the user to easily combine different modules depending on the required processing steps. \n",
    "\n",
    "In this notebook we will show you how to use the Oligo Designer Toolsuite to develop your own custom oligo design pipeline. \n",
    "Therefore, we choose the *SCRINSHOT* protocol, which needs customized padlock probes. The design of padlock probes for the *SCRINSHOT* protocol is described in detail in the supplemental material of [*Sountoulidis, Alexandros, et al. \"SCRINSHOT enables spatial mapping of cell states in tissue sections with single-cell resolution.\" PLoS biology 18.11 (2020): e3000675.*](\n",
    "https://doi.org/10.1371/journal.pbio.3000675)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the necassary pakages exept the packages from the oligo_designer_toolsuite\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import shutil"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the parameters\n",
    "\n",
    "First, we need to define the parameters we want to use to generate the Padlock probes. \n",
    "A possible way to define all the parameters, that is flexible and reusable, is to use a configuration file. \n",
    "For this tutorial we will use the YAML file `padlock_probe_designer_custom.yaml`, which uses a custom gene annotation (GTF file - GFF3 not supported) and genome sequence (fasta file). As an example, we use the human gene annotation and genome sequence of chromsome 16. Check out the config file to understand which parameters are required and how the configuration file is structured.\n",
    "If you want to use NCBI or Ensembl gene annotation and genome sequence with automatic file download from their servers, please check out the YAML files `padlock_probe_designer_ncbi.yaml` and `padlock_probe_designer_ensembl.yaml`.\n",
    "\n",
    "Once the configuration file has been set up we have to read its content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_package = os.path.dirname(os.getcwd())\n",
    "sys.path.append(dir_package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = os.path.join(dir_package, \"data/configs/scrinshot_probe_designer_custom.yaml\") # custom config\n",
    "# config_file = os.path.join(dir_package, \"data/configs/padlock_probe_designer_ncbi.yaml\") # NCBI config\n",
    "# config_file = os.path.join(dir_package, \"data/configs/padlock_probe_designer_ensemble.yaml\") # Ensemble config\n",
    "\n",
    "with open(config_file, 'r') as yaml_file:\n",
    "    config = yaml.safe_load(yaml_file)\n",
    "dir_output = os.path.join(dir_package, config[\"dir_output\"]) # create the complete path for the output directory\n",
    "\n",
    "# only needed when custom config used\n",
    "config[\"source_params\"][\"file_annotation\"] = os.path.join(dir_package, config[\"source_params\"][\"file_annotation\"]) \n",
    "config[\"source_params\"][\"file_sequence\"] = os.path.join(dir_package, config[\"source_params\"][\"file_sequence\"]) \n",
    "config[\"file_genes\"] = os.path.join(dir_package, config[\"file_genes\"]) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Genomic Regions for the Oligo and Reference Database\n",
    "\n",
    "Now we can start to build the pipeline. We start with generating the fasta file used as basis for the oligo database and reference database for the alignement methods.  \n",
    "*Note: you can use different fasta files to create the oligo and reference database.*  \n",
    "\n",
    "From the provided genome annotation (fasta file), specific regions can be extracted. In particular, it is possible to use: \n",
    "\n",
    "- the whole genome\n",
    "- the transcriptome\n",
    "- the coding sequence (CDS)\n",
    "\n",
    "To create specific regions, we need a `CustomGenomicRegionGenerator`, or a class that inherits from it (e.g. `NcbiGenomicRegionGenerator` and `EnsemblGenomicRegionGenerator`) and call the method `generate_transcript_reduced_representation()` to extract the transcriptome in a reduced representation form from the given files. These classes differ on how the the fasta and the GTF (GFF3 not supported) files used are obtained. The first one uses local files while the others dowload them respectively form the NCBI or Ensambl ftp server. *Note: that the GTF file must contain coordinate as well as transcript ID and exon number infomration to generate a transcriptome or coding sequence.* In the output fasta file, the header of each sequence starts with '>' and contain the following information: \n",
    "region_id, additional_information and coordinates (chrom, start, end, strand)\n",
    "\n",
    "Output Format (per sequence):  \n",
    "`>region_id::additional information::chromosome:start-end(strand)`  \n",
    "`sequence`\n",
    "\n",
    "Example:  \n",
    "`>ASR1::transcrip_id=XM456,exon_number=5::16:54552-54786(+)`  \n",
    "`AGTTGACAGACCCCAGATTAAAGTGTGTCGCGCAACAC` \n",
    "\n",
    "To use NCBI or Ensembl files, comment in the respective config files in the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oligo_designer_toolsuite.database import CustomGenomicRegionGenerator, NcbiGenomicRegionGenerator, EnsemblGenomicRegionGenerator\n",
    "\n",
    "region_generator = CustomGenomicRegionGenerator(\n",
    "    annotation_file=config[\"source_params\"][\"file_annotation\"], \n",
    "    sequence_file=config[\"source_params\"][\"file_sequence\"], \n",
    "    files_source=config[\"source\"], \n",
    "    species=config[\"source_params\"][\"species\"], \n",
    "    annotation_release=config[\"source_params\"][\"annotation_release\"], \n",
    "    genome_assembly=config[\"source_params\"][\"genome_assembly\"],\n",
    "    dir_output=dir_output\n",
    ")\n",
    "# # If the Ncbi config file is selected\n",
    "# region_generator = NcbiGenomicRegionGenerator(\n",
    "#     taxon=config[\"source_params\"][\"taxon\"],\n",
    "#     species=config[\"source_params\"][\"species\"], \n",
    "#     annotation_release=config[\"source_params\"][\"annotation_release\"], \n",
    "#     dir_output=dir_output\n",
    "# )\n",
    "# # If the Ensembl config file is generated\n",
    "# region_generator = EnsemblGenomicRegionGenerator(\n",
    "#     species=config[\"source_params\"][\"species\"], \n",
    "#     annotation_release=config[\"source_params\"][\"annotation_release\"], \n",
    "#     dir_output=dir_output\n",
    "# )\n",
    "file_transcriptome = region_generator.generate_transcript_reduced_representation(include_exon_junctions=True, exon_junction_size=2*config[\"probe_length_max\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oligo sequences generation\n",
    "\n",
    "\n",
    "Next we will generate all the possible oligos with length between the minimum and maximum value, belonging to the genes defined in the config file. Therefore, we intialize the class ``OligoDatabase`` and use the method ``create_database()``.  \n",
    "The ``OligoDatabase`` requires a fasta file as input. This fasta file can be created using a ``GenomicRegionGenerator`` (see code in cell above) or a custom fasta file can be provided. The input fasta file needs a header for each sequence, which must start with '>' and contain the following information: \n",
    "region_id, additional_information and coordinates (chrom, start, end, strand), where the region_id is compulsory and the other fileds are optional.\n",
    "\n",
    "Input Format (per sequence):  \n",
    "`>region_id::additional information::chromosome:start-end(strand)`  \n",
    "`sequence`\n",
    "\n",
    "Example:  \n",
    "`>ASR1::transcrip_id=XM456,exon_number=5::16:54552-54786(+)`  \n",
    "`AGTTGACAGACCCCAGATTAAAGTGTGTCGCGCAACAC`  \n",
    "or   \n",
    "`>ASR1`  \n",
    "`AGTTGACAGACCCCAGATTAAAGTGTGTCGCGCAACAC`\n",
    "\n",
    "The generated probes will be saved in a nested dicionary with the following structure: \n",
    "\n",
    "``[gene][oligo_id][oligo_features]``\n",
    "\n",
    "*Note: if you already have a stored database you can load it into an OligoDatabase object by using the ``load_oligo_database()`` function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oligo_designer_toolsuite.database import OligoDatabase\n",
    "\n",
    "# define the database class\n",
    "oligo_database = OligoDatabase(\n",
    "    min_oligos_per_region = config[\"min_probes_per_gene\"],\n",
    "    files_source = region_generator.files_source,\n",
    "    species = region_generator.species,\n",
    "    annotation_release = region_generator.annotation_release,\n",
    "    genome_assembly = region_generator.genome_assembly,\n",
    "    n_jobs = 2,\n",
    "    dir_output=dir_output\n",
    ")\n",
    "\n",
    "# read the genes file\n",
    "with open(config[\"file_genes\"]) as handle:\n",
    "    lines = handle.readlines()\n",
    "    genes = [line.rstrip() for line in lines]\n",
    "    \n",
    "#generate the oligo sequences from gene transcripts\n",
    "oligo_database.create_database(file_fasta = file_transcriptome, oligo_length_min = config[\"probe_length_min\"], oligo_length_max = config[\"probe_length_max\"],region_ids = genes)\n",
    "\n",
    "# alternative: load database from file\n",
    "# oligo_database.load_oligo_database(file_database)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary structure\n",
    "\n",
    "Here is an example of how the nested dictionary is structured for one oligo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AARS1': {'AARS1_16:70265624-70265662(-)': {'sequence': Seq('GAGACACTGCTTGGCTCCTCTATGACACCTATGGGTTT'), 'chromosome': '16', 'start': [70265624], 'end': [70265662], 'strand': '-', 'length': 38, 'additional_information_fasta': ['transcript_id=NM_001605.3,exon_number=10;transcript_id=XM_047433666.1,exon_number=10']}}}\n"
     ]
    }
   ],
   "source": [
    "gene = list(oligo_database.database.keys())[0]\n",
    "oligo_id = list(oligo_database.database[gene].keys())[0]\n",
    "\n",
    "sample_oligos_DB = {gene: {oligo_id: oligo_database.database[gene][oligo_id]}}\n",
    "print(sample_oligos_DB)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and write\n",
    "\n",
    "The ``OligoDatabase`` class deals with everything that is related to the management of the database. In particular, beyond creatig the database, it can also read and write the oligo sequences in a **tsv** fromat. The methods `load_database()` and `write_database()`,  have exactly this purpose. It is also possible to write the sequences as a fasta file with the method ``write_fasta_from_database()``.\n",
    "\n",
    "This allows us to save the current state of the database during the pipeline and to retrive it form a previous stage if an error uccurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"write_intermediate_steps\"]:\n",
    "    file_database = oligo_database.write_database(filename=\"probe_database_initial.txt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Property filters\n",
    "\n",
    "Once all the possible sequences are created, we apply a first filtering step based on the sequence properties (e.g. melting temperature or GC content). This is useful to reduce the amount of sequences we have to deal with in the next stages and discard all the sequences that are not suited for the experiment.\n",
    "\n",
    "Each property filter is a class that inherits from the Abstact Base Class `PropertyFilterBase`. They have a method called `apply` that takes the `OligoDatabase.database` dictionary and returns it filtered. To make this process smooth and modular the wrapper class `PropertyFilter` allows to apply several filters one after the other. It takes as input a list of filter classes and an `OligoDatabase` object and applies sequentially all the filters and returns the final filterd version of the database. Additionally, all the necessary sequence features computed by the filters are stored in the `OligoDatabase.database` for possible later use. \n",
    "\n",
    "*Note: the filters are applied in the order they are given as input. Hence, filter with fast computations should be listed first, i.e. apply GC content filter before melting temperature filter, to reduce runtime.*\n",
    "\n",
    "To create new property filters follow the Abstact Base Class requirements in `PropertyFilterBase`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oligo_designer_toolsuite.oligo_property_filter import (\n",
    "    PropertyFilter,\n",
    "    MaskedSequences,\n",
    "    GCContent, \n",
    "    MeltingTemperatureNN, \n",
    "    PadlockArms\n",
    ")\n",
    "from Bio.SeqUtils import MeltingTemp as mt\n",
    "\n",
    "# the melting temperature params need to be preprocessed\n",
    "Tm_params = config[\"Tm_parameters_probe\"]\n",
    "Tm_params[\"nn_table\"] = getattr(mt, Tm_params[\"nn_table\"])\n",
    "Tm_params[\"tmm_table\"] = getattr(mt, Tm_params[\"tmm_table\"])\n",
    "Tm_params[\"imm_table\"] = getattr(mt, Tm_params[\"imm_table\"])\n",
    "Tm_params[\"de_table\"] = getattr(mt, Tm_params[\"de_table\"])\n",
    "\n",
    "Tm_chem_correction_param = config[\"Tm_chem_correction_param_probe\"]\n",
    "\n",
    "# initialize the filters clasees\n",
    "masked_sequences = MaskedSequences()\n",
    "gc_content = GCContent(GC_content_min=config[\"GC_content_min\"], GC_content_max=config[\"GC_content_max\"])\n",
    "melting_temperature = MeltingTemperatureNN(\n",
    "    Tm_min=config[\"Tm_min\"], \n",
    "    Tm_max=config[\"Tm_max\"], \n",
    "    Tm_parameters=Tm_params, \n",
    "    Tm_chem_correction_parameters=Tm_chem_correction_param\n",
    ")\n",
    "padlock_arms = PadlockArms(\n",
    "    min_arm_length=config[\"min_arm_length\"],\n",
    "    max_arm_Tm_dif=config[\"max_arm_Tm_dif\"],\n",
    "    arm_Tm_min=config[\"arm_Tm_min\"],\n",
    "    arm_Tm_max=config[\"arm_Tm_max\"],\n",
    "    Tm_parameters=Tm_params,\n",
    "    Tm_chem_correction_parameters=Tm_chem_correction_param,\n",
    ")\n",
    "# create the list of filters\n",
    "filters = [masked_sequences, gc_content, melting_temperature, padlock_arms]\n",
    "\n",
    "# initialize the property filter class\n",
    "property_filter = PropertyFilter(filters=filters)\n",
    "# filter the database\n",
    "oligo_database = property_filter.apply(oligo_database=oligo_database, n_jobs=config[\"n_jobs\"])\n",
    "# write the intermediate result in a file\n",
    "if config[\"write_intermediate_steps\"]:\n",
    "    file_database = oligo_database.write_database(filename=\"probe_database_property_filter.txt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specificity filters\n",
    "\n",
    "In experiments using short oligos one of the main problem that can occur are off-target binding of the designed oligo sequences to undesired target regions. To avoid this problem we can decide to remove all the oligos that also align to regions outside the gene they belong to.\n",
    "\n",
    "The classes in the subpackage `oligo_speificity_filters` detect these oligos using alignment methods such as Blast and Bowtie and remove them from the database. The currently implemeted classes are: `ExactMatches`, `Blastn`, `Bowtie`, `Bowtie2`, `BowtieSeedRegion`. Look at the documentation for detailed information. Those filters are structured in the same way as the property filters. A second class `SpecificityFilter` takes a list of all the filters we want to apply, and applies them sequentially to the `OligoDatabase.database`.  \n",
    "*Note: the filters are applied in the order they are given as input. Hence, filter with fast computations should be listed first, i.e. apply exact match filter before Blastn filter, to reduce runtime.*\n",
    "\n",
    "In addition, alignement methods need a reference fasta file to detect the off-target regions. The `CustomGenomicRegionGenerator` class provides the possibility to generate this reference region as shown proviously. Once the fasta file has been created the class `ReferenceDatabase` stores the path, additional information and can extract regions we are interested in from the fasta file.\n",
    "\n",
    "*Note: it is possible to apply a set of specificity filters with a reference file and a second set with a different reference file.*\n",
    "\n",
    "For our pipeline, we will use `ExactMatches` and `Blastn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oligo_designer_toolsuite.database import ReferenceDatabase\n",
    "from oligo_designer_toolsuite.oligo_specificity_filter import (\n",
    "    SpecificityFilter,\n",
    "    ExactMatches,\n",
    "    Blastn,\n",
    ")\n",
    "\n",
    "dir_specificity = os.path.join(dir_output, \"specificity_temporary\") # folder where the temporary files will be written\n",
    "\n",
    "\n",
    "reference = ReferenceDatabase(\n",
    "    file_fasta = file_transcriptome,\n",
    "    files_source = region_generator.files_source,\n",
    "    species = region_generator.species,\n",
    "    annotation_release = region_generator.annotation_release,\n",
    "    genome_assembly = region_generator.genome_assembly,\n",
    "    dir_output=dir_output\n",
    "    )\n",
    "\n",
    "# intialize the filter classes\n",
    "exact_matches = ExactMatches(dir_specificity=dir_specificity)\n",
    "blastn = Blastn(\n",
    "    dir_specificity=dir_specificity, \n",
    "    word_size=config[\"blast_word_size\"],\n",
    "    percent_identity=config[\"blast_percent_identity\"],\n",
    "    coverage=config[\"blast_coverage\"],\n",
    "    strand=\"plus\",\n",
    ")\n",
    "filters = [exact_matches, blastn]\n",
    "\n",
    "# initialize the specificity filter class\n",
    "specificity_filter = SpecificityFilter(filters=filters)\n",
    "# filter the database\n",
    "oligo_database = specificity_filter.apply(oligo_database=oligo_database, reference_database=reference, n_jobs=config[\"n_jobs\"])\n",
    "# write the intermediate result\n",
    "if config[\"write_intermediate_steps\"]:\n",
    "    file_database = oligo_database.write_database(filename=\"blast_database_specificity_filter.txt\")\n",
    "\n",
    "shutil.rmtree(dir_specificity)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oligoset generation\n",
    "\n",
    "In the next step of the pipeline the oligos will be choosen according to their theoretical efficiency in the experiment scope (e.g. how well they bind to their target). Each oligo will receive a score computed by a class that inherits from `OligoScoringBase`. Later, the sequences will be organized in sets and a class inheriting from `SetScoringBase` will give a general efficiency score to the set. At the end the best sets will be selected and scored.\n",
    "\n",
    "For our pipeline, it is required that the each set of sequences contains oligos that do not overlap. In fact, if two oligos were overlapping, they would compete binding to the same target and their efficiency would drop. Therefore, we only consider sets of non-overlapping oligos.\n",
    "\n",
    "The class `OligosetGenerator` takes the scoring strategies and tries to find, among all the feasible non-overlapping sets of oligos, the sets with the best efficiency scores. These sets will be save in a pandas DataFrame with the following structure:\n",
    "\n",
    "\n",
    " oligoset_id | oligo_0  | oligo_1  | oligo_2  |  ...  | oligo_n  | set_score_1 | set_score_2 |  ...  \n",
    "------------ | -------- | -------- | -------- | ----- | -------- | ----------- | ----------- | ------:\n",
    " 0           | AGRN_184 | AGRN_133 | AGRN_832 |  ...  | AGRN_706 | 0.3445      | 1.2332      |  ...  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oligo_designer_toolsuite.oligo_efficiency_filter import(\n",
    "    PadlockOligoScoring,\n",
    "    PadlockSetScoring,\n",
    ")\n",
    "from oligo_designer_toolsuite.oligo_selection import OligosetGenerator, padlock_heuristic_selection\n",
    "\n",
    "# initialize the scoring classes\n",
    "oligos_scoring = PadlockOligoScoring(\n",
    "    Tm_min=config[\"Tm_min\"],\n",
    "    Tm_opt=config[\"Tm_opt\"],\n",
    "    Tm_max=config[\"Tm_max\"],\n",
    "    GC_content_min=config[\"GC_content_min\"],\n",
    "    GC_content_opt=config[\"GC_content_opt\"],\n",
    "    GC_content_max=config[\"GC_content_max\"],\n",
    "    Tm_weight=config[\"Tm_weight\"],\n",
    "    GC_weight=config[\"GC_weight\"],\n",
    ")\n",
    "set_scoring = PadlockSetScoring()\n",
    "\n",
    "# initialize the oligoset generator class\n",
    "oligoset_generator = OligosetGenerator(\n",
    "    oligoset_size=config[\"probeset_size_opt\"], \n",
    "    min_oligoset_size=config[\"probeset_size_min\"],\n",
    "    oligos_scoring=oligos_scoring,\n",
    "    set_scoring=set_scoring,\n",
    "    heurustic_selection=padlock_heuristic_selection,\n",
    ")\n",
    "\n",
    "# generate the oligoset\n",
    "oligo_database = oligoset_generator.apply(oligo_database=oligo_database, n_sets=config[\"n_sets\"], n_jobs=config[\"n_jobs\"])\n",
    "# write the intermediate result\n",
    "if config[\"write_intermediate_steps\"]:\n",
    "    file_database = oligo_database.write_database(filename=\"probe_database_oligosets.txt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last step\n",
    "\n",
    "Once the best oligosets are generated each experiment design might require (or not) an addtional step. In the case of the *SCRINSHOT* protocol the last step consists in designing the final padlock probe sequences containing the padlock probe and detection probe sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oligo_designer_toolsuite.sequence_design import PadlockSequence\n",
    "\n",
    "# preprocessing of the melting temperature parameters\n",
    "Tm_params = config[\"Tm_parameters_detection_oligo\"]\n",
    "Tm_params[\"nn_table\"] = getattr(mt, Tm_params[\"nn_table\"])\n",
    "Tm_params[\"tmm_table\"] = getattr(mt, Tm_params[\"tmm_table\"])\n",
    "Tm_params[\"imm_table\"] = getattr(mt, Tm_params[\"imm_table\"])\n",
    "Tm_params[\"de_table\"] = getattr(mt, Tm_params[\"de_table\"])\n",
    "\n",
    "Tm_chem_correction_parameters = config[\"Tm_chem_correction_param_detection_oligo\"]\n",
    "\n",
    "# initilize the padlock sequence designer class\n",
    "padlock_sequence = PadlockSequence(\n",
    "    detect_oligo_length_min=config[\"detect_oligo_length_min\"],\n",
    "    detect_oligo_length_max=config[\"detect_oligo_length_max\"],\n",
    "    detect_oligo_Tm_opt=config[\"detect_oligo_Tm_opt\"],\n",
    "    Tm_parameters=Tm_params,\n",
    "    Tm_chem_correction_parameters=Tm_chem_correction_parameters,\n",
    "    dir_output = dir_output\n",
    ")\n",
    "# generate the padlock sequence\n",
    "padlock_sequence.design_final_padlock_sequence(oligo_database=oligo_database)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ODT",
   "language": "python",
   "name": "odt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ff94d65164c54a2126c7dc0869520902e3a005d5dddb9f8c3667ad0fd9373c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
